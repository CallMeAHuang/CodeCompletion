{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liq/.conda/envs/law/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /home/liq/sjw/ASE-COPY\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "# 指定要设置的目标目录\n",
    "target_directory = \"/home/liq/sjw/ASE-COPY/hybrid_code/\"\n",
    "os.chdir(target_directory)\n",
    "from utils import *\n",
    "target_directory = \"/home/liq/sjw/ASE-COPY/\"\n",
    "# 设置当前工作目录为指定目录\n",
    "os.chdir(target_directory)\n",
    "# 打印当前工作目录，以确认是否已经改变\n",
    "print(\"当前工作目录:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(model_type='unixCoder', pretrain_dir='../transformers/unixcoder-base/', lit_file='./dataset/intra_scenario_completion/java/literals.json', data_dir=None, langs='java', output_dir=None, seed=42, max_chunk_len=300, block_k=10, token_k=20, data_process=False, build_index=False, do_search=False, do_generate=False, use_dense=False, use_bm25=False, use_hybrid=False, bm_name='bm25', clearml_proj_name='', log_file='log.log', device=device(type='cuda', index=0))\n"
     ]
    }
   ],
   "source": [
    "def add_args(parser):\n",
    "    # 预训练模型相关\n",
    "    parser.add_argument(\"--model_type\", default=\"unixCoder\", type=str,\n",
    "                        help=\"The model architecture to be fine-tuned.\")\n",
    "    parser.add_argument(\"--pretrain_dir\", default=\"../transformers/unixcoder-base/\", type=str,\n",
    "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "    parser.add_argument(\"--lit_file\", default=\"./dataset/intra_scenario_completion/java/literals.json\", type=str,help=\"literals json file\")\n",
    "\n",
    "    # 待补全文件相关\n",
    "    parser.add_argument(\"--data_dir\", default=None, type=str,\n",
    "                        help=\"The input data path.\")\n",
    "    parser.add_argument(\"--langs\", default=\"java\", type=str, \n",
    "                        help=\"Languages to train, if all, train all languages in data_dir\")\n",
    "    parser.add_argument(\"--output_dir\", default=None, type=str, \n",
    "                        help=\"The output directory where the model predictions and checkpoints will be written.\")\n",
    "    \n",
    "    # 检索相关\n",
    "    parser.add_argument(\"--seed\", default=42, type=int)\n",
    "    parser.add_argument(\"--max_chunk_len\", default=300, type=int)\n",
    "    parser.add_argument(\"--block_k\", default=10, type=int)\n",
    "    parser.add_argument(\"--token_k\", default=20, type=int)\n",
    "\n",
    "    # 命令相关\n",
    "    parser.add_argument(\"--data_process\", action=\"store_true\")\n",
    "    parser.add_argument(\"--build_index\", action='store_true')\n",
    "    parser.add_argument(\"--do_search\", action='store_true')\n",
    "    parser.add_argument(\"--do_generate\", action='store_true')\n",
    "    parser.add_argument(\"--use_dense\", action='store_true')\n",
    "    parser.add_argument(\"--use_bm25\", action='store_true')\n",
    "    parser.add_argument(\"--use_hybrid\", action='store_true')\n",
    "    parser.add_argument(\"--bm_name\", default=\"bm25\", type=str, required=False, help=\"elasticsearch name.\")\n",
    "    parser.add_argument('--clearml_proj_name', type=str, default='')\n",
    "    parser.add_argument('--log_file', type=str, default='log.log')\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "add_args(parser)\n",
    "args = parser.parse_args(args=[])\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.device = device\n",
    "print(args)\n",
    "special_tokens = get_special_tokens(args.lit_file)\n",
    "tokenizer, model = load_pretrained_model(args, special_tokens)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "inputs = torch.load('cands.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hybrid_code.knn_build import *\n",
    "knn_saver = KNNSaver(dimension=model.config.hidden_size, pad_id=tokenizer.pad_token_id,\n",
    "                                 only_errors=False)\n",
    "knn_saver.break_into(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0267, -0.0175, -0.1783,  ...,  0.7205,  1.5530, -0.6935],\n",
      "        [ 0.0267, -0.0175, -0.1783,  ...,  0.7205,  1.5530, -0.6935],\n",
      "        [ 0.0267, -0.0175, -0.1783,  ...,  0.7205,  1.5530, -0.6935],\n",
      "        ...,\n",
      "        [ 2.0536, -1.3802,  1.7088,  ...,  0.3719,  1.4268,  0.7988],\n",
      "        [ 2.1275, -0.7531,  1.4362,  ...,  0.6786,  1.6657,  0.9966],\n",
      "        [ 1.8327,  0.2165,  2.6935,  ..., -0.1264,  2.3622,  0.7895]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model(inputs, labels=inputs)\n",
    "    print(knn_saver.dstore_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_saver.break_out()\n",
    "del knn_saver\n",
    "from hybrid_master.knn_build import *\n",
    "knn_saver = KNNSaver(dimension=model.config.hidden_size, pad_id=tokenizer.pad_token_id,\n",
    "                                 only_errors=False)\n",
    "knn_saver.break_into(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0267, -0.0175, -0.1783,  ...,  0.7205,  1.5530, -0.6935],\n",
      "        [ 0.0267, -0.0175, -0.1783,  ...,  0.7205,  1.5530, -0.6935],\n",
      "        [ 0.0267, -0.0175, -0.1783,  ...,  0.7205,  1.5530, -0.6935],\n",
      "        ...,\n",
      "        [ 2.0536, -1.3802,  1.7088,  ...,  0.3719,  1.4268,  0.7988],\n",
      "        [ 2.1275, -0.7531,  1.4362,  ...,  0.6786,  1.6657,  0.9966],\n",
      "        [ 1.8327,  0.2165,  2.6935,  ..., -0.1264,  2.3622,  0.7895]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model(inputs[:-1], labels=inputs[:-1])\n",
    "    print(knn_saver.dstore_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output1['past_key_values'][0][0].shape)\n",
    "past_key_values = list(output1['past_key_values'])\n",
    "print(type(past_key_values))\n",
    "for temp in range(len(past_key_values)):\n",
    "    print(temp)\n",
    "    print(len(past_key_values[temp]))\n",
    "    print(past_key_values[temp][0].shape)\n",
    "    print(past_key_values[temp][1].shape)\n",
    "    print(past_key_values[temp][0][-1][:,:5,:].unsqueeze(0).shape)\n",
    "    past_key_values[temp][0] = past_key_values[temp][0][-1][:,:5,:].unsqueeze(0)\n",
    "    past_key_values[temp][1] = past_key_values[temp][1][-1][:,:5,:].unsqueeze(0)\n",
    "import torch\n",
    "logits = torch.load('logits.pth')\n",
    "output_logits = torch.load('output_logits.pth')\n",
    "queries = torch.load('queries.pth')\n",
    "output_queries = torch.load('output_querys.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test_past1.pkl', 'rb') as file:\n",
    "    past1 = pickle.load(file)\n",
    "with open('test_past2.pkl', 'rb') as file:\n",
    "    past2 = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
